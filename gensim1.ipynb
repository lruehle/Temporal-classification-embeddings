{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298eb686",
   "metadata": {},
   "source": [
    "based on https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d6742",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e1bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "import inspect\n",
    "import os\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a934e",
   "metadata": {},
   "source": [
    "### Prepare own corpus\n",
    "\n",
    "possible fairy tales: \n",
    "\n",
    "    * Maarouf, Ismaïl El and Jeanne Villaneau. “A French Fairy Tale Corpus syntactically and semantically annotated.” LREC (2012).\n",
    "    \n",
    "    * Vicente, Marta & Miró, María & Lloret, Elena & Suárez Cueto, Armando. (2021). Leveraging Machine Learning to Explain the Nature of Written Genres. IEEE Access. PP. 1-1. 10.1109/ACCESS.2021.3056927. \n",
    "    \n",
    "    * Ragan, Kathleen. (2009). What Happened to the Heroines in Folktales?: An Analysis by Gender of a Multicultural Sample of Published Folktales Collected from Storytellers. Marvels & Tales. 23. 227-247. 10.1353/mat.0.0128. \n",
    "    \n",
    "    * Jeana Jorgensen. “Quantifying the Grimm Corpus: Transgressive and Transformative Bodies in the Grimms’ Fairy Tales.” Marvels & Tales 28, no. 1 (2014): 127–41. https://doi.org/10.13110/marvelstales.28.1.0127.\n",
    "    \n",
    "    * Silva, R. S. (2012). Fairy tales and moral values: a corpus-based approach. BELT - Brazilian English Language Teaching Journal, 3(1). Retrieved from https://revistaseletronicas.pucrs.br/ojs/index.php/belt/article/view/10326\n",
    "    \n",
    "    * Walter Maik (2022).´Märchenkorpus Version 1.0 (1.0)´ Humboldt-Universität zu Berlin, 2022. Homepage: http://www.textbewegung.de/. DOI: https://doi.org/10.34644/laudatio-dev-UyRUCnMB7CArCQ9C63ji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa25c84",
   "metadata": {},
   "source": [
    "### Paths and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3529b616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Python\\Gensim_tutorial\\gensim1.ipynb\n",
      "D:\\Develop\\Python\\Gensim_tutorial\\corpora\\Laudatio\n",
      "D:\\Develop\\Python\\Gensim_tutorial\\corpora\\Laudatio\\grimm_aschenputtel_119-126.txt\n",
      "D:\\Develop\\Python\\Gensim_tutorial\\tmp\n"
     ]
    }
   ],
   "source": [
    "#get project path\n",
    "dn = os.path.abspath('gensim1.ipynb')\n",
    "print(dn)\n",
    "\n",
    "\n",
    "#get path to corpus\n",
    "td = os.path.join(os.path.dirname(dn),'corpora\\Laudatio\\grimm_aschenputtel_119-126.txt')\n",
    "corpora_dir = os.path.join(os.path.dirname(dn),'corpora\\Laudatio')\n",
    "temp_dir=os.path.join(os.path.dirname(dn),'tmp')\n",
    "print(corpora_dir)\n",
    "print(td)\n",
    "print(temp_dir)\n",
    "#tokens = [simple_preprocess(sentence, deacc=True) for sentence in open(td)]\n",
    "#gensim_dic = corpora.Dictionary()\n",
    "#gc = [gensim_dic.doc2bow(token, allow_update=True) for token in tokens]\n",
    "#word_freq = [[(gensim_dic[id], frequence) for id, frequence in couple] for couple in gc]\n",
    "#print(word_freq)\n",
    "\n",
    "\n",
    "\n",
    "#multiple doc:\n",
    "mult_data = os.scandir(corpora_dir)\n",
    "#corp_txt = [[print(document)]for documents in (open(mult_data, encoding=\"utf-8\"))]\n",
    "laudatio_files = [os.path.join(corpora_dir,entry.name) for entry in mult_data if entry.is_file()]\n",
    "mult_data.close()\n",
    "#print(laudatio_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0527de8a",
   "metadata": {},
   "source": [
    "### Create Gensim Corpus from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd5a5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single Doc\n",
    "\n",
    "#path\n",
    "data = open(td, encoding=\"utf-8\")\n",
    "txt = [[word for word in document.lower().split()] for document in data]\n",
    "#print(txt)\n",
    "dictionary1 = corpora.Dictionary(txt)#\n",
    "#print(dictionary.token2id) #prints word and their ids\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open(td):\n",
    "            yield dictionary1.doc2bow(line.lower().split()) #check dov2bow function\n",
    "nc_b = MyCorpus()\n",
    "for vector in nc_b:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68781da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<297 unique tokens: ['als', 'andere', 'auf', 'darauf', 'das']...>\n"
     ]
    }
   ],
   "source": [
    "#construct a dictionary\n",
    "dictionary2 = corpora.Dictionary(line.lower().split() for line in open(td))\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "stop_ids =[\n",
    "    dictionary2.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in dictionary2.token2id\n",
    "]\n",
    "once_ids=[tokenid for tokenid, docfreq in dictionary2.dfs.items() if docfreq==1]\n",
    "dictionary2.filter_tokens(stop_ids + once_ids)\n",
    "dictionary2.compactify()\n",
    "print(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25ccf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple documents:\n",
    "class MyCorpora:\n",
    "    def __iter__(self):\n",
    "        for entry in laudatio_files:\n",
    "            for line in open(entry, encoding=\"utf-8\"):\n",
    "                yield simple_preprocess(line,deacc=True,min_len=4,max_len=20) \n",
    "\n",
    "nc = MyCorpora()\n",
    "mult_dict = corpora.Dictionary(nc)\n",
    "#print(len(mult_dict))\n",
    "#for vector in nc:\n",
    " #   print(vector)\n",
    "\n",
    "# further processing\n",
    "#min_len/stop words macht vielleicht keinen Sinn, da selbst diese Worte Einfluss haben sollen? evtl. überprüfen, wie sich diese Verändern\n",
    "stoplist = set('in für auf der die das mit weil'.split()) #existieren diese Worte überhaupt? oben ist min_len ja bei 4. => nope stop words sind eh schon draußen\n",
    "stop_ids =[ #map stopwords to an id\n",
    "    mult_dict.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in mult_dict.token2id\n",
    "]\n",
    "once_ids=[tokenid for tokenid, docfreq in mult_dict.dfs.items() if docfreq==1] #<2?\n",
    "\n",
    "mult_dict.filter_tokens(once_ids + stop_ids) #remove tokens from once (& stop)\n",
    "mult_dict.compactify()\n",
    "#print(len(mult_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319323ef",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d9ecc",
   "metadata": {},
   "source": [
    "#### train & save Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc88c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=nc, vector_size=100, window=7, min_count=2, epochs=100)\n",
    "model.save(\"frst_word2vec.model\")#saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af35904",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=model.wv\n",
    "word_vectors.save(\"frst_word2vec.wordvectors\") #saving vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8158a07",
   "metadata": {},
   "source": [
    "#### load & use Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46a842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gemahlin', 0.5540225505828857), ('ankunft', 0.5036059617996216), ('schwester', 0.4301741123199463), ('sohne', 0.4143478274345398), ('bedingung', 0.4048870801925659), ('liebste', 0.3980526626110077), ('frau', 0.3977101147174835), ('holzhauer', 0.3972511291503906), ('mienen', 0.39202576875686646), ('braut', 0.39059847593307495)]\n"
     ]
    }
   ],
   "source": [
    "wv=KeyedVectors.load(\"frst_word2vec.wordvectors\", mmap='r')\n",
    "vector = wv['frau']\n",
    "#print(vector)\n",
    "print(wv.most_similar('tochter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac294841",
   "metadata": {},
   "source": [
    "Next steps: diachronic corpus (vllt 3 times?), check preprocessing, check creation of classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa32353",
   "metadata": {},
   "source": [
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html#corpus-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31260d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[(1, 0.5)], []]\n",
    "corpora.MmCorpus.serialize(os.path.join(temp_dir,'corpus1.mm'),corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar('book'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675e111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('gensim_fst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f9f3b72917c79e99bfdf74100fc424b209099025a579112ace27dba1421c8d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
